{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dicipulo, Earl Geibriel S."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrxbKKJZtPzj"
      },
      "source": [
        "# **Activity 2: Python-Pandas Exercise**\n",
        "\n",
        "Objectives:\n",
        "- Understand Python syntax (variables, loops, functions).\n",
        "- Learn Pandas basics (Series, DataFrames, reading files).\n",
        "- Perform data cleaning (handling missing values, correcting formats, removing duplicates).\n",
        "- Apply concepts in a real-world case study."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNQbxlCPtvXZ"
      },
      "source": [
        "# Part 1: Hands-on Python & Pandas Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH2WqeaY38NC"
      },
      "source": [
        "1. Install the Pandas library in your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPhWF_2u5Qxy"
      },
      "outputs": [],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZC17Lf1zT3Q"
      },
      "source": [
        "2. Import the  pandas package under the name `pd`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lR6fv9XE3Pw3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO_MlGtx3Wj5"
      },
      "source": [
        "3. Print the pandas version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y4lcL4Nb3SrJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.2.3\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "print(pd.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWJFiRZ03pwH"
      },
      "source": [
        "4. Create a variable `x` with the value 10 and a string variable `y` with \"Fortes in Fide!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCkALKg_3vig"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n",
            "Fortes in Fide!\n"
          ]
        }
      ],
      "source": [
        "x = 10\n",
        "y = 'Fortes in Fide!'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBzRK3sY5Wfh"
      },
      "source": [
        "5. Define a list with numbers `[1, 2, 3, 4, 5]` and a dictionary with keys `name` and `age`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8Zg7dgz5XPA"
      },
      "outputs": [],
      "source": [
        "a = [1, 2, 3, 4, 5]\n",
        "b = {\n",
        "    \"name\",\n",
        "    \"key\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbsHcq7w5hE2"
      },
      "source": [
        "6. Write a function `greet(name)` that returns \"Magis, (name)\"!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LHKMev_a5mJX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Magis, Earl !\n"
          ]
        }
      ],
      "source": [
        "def greet(fname):\n",
        "    print(\"Magis,\", fname, \"!\")\n",
        "\n",
        "greet(\"Earl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_UBbRZKYBFF"
      },
      "source": [
        "7. Write a Python function that takes a user‚Äôs name as input and prints a personalized greeting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8T6ocVeYCnD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello Earl !\n"
          ]
        }
      ],
      "source": [
        "def greet(username):\n",
        "    print(\"Good day to you,\", username, \"!\")\n",
        "\n",
        "username = input(\"Enter username:\")\n",
        "greet(username)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GEjHQ-PYRj2"
      },
      "source": [
        "8. Modify **Number 7** that if the user does not enter a name, it defaults to \"Guest\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rYfMyyQeYbf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Good day to you, Guest !\n"
          ]
        }
      ],
      "source": [
        "def greet(username):\n",
        "    print(\"Good day to you,\", username, \"!\")\n",
        "\n",
        "username = \"Guest\"\n",
        "greet(username)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG-Ubf3259sb"
      },
      "source": [
        "9. Create a Pandas Series from `[10, 20, 30, 40]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGThKfqQ5-sj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    10\n",
            "1    20\n",
            "2    30\n",
            "3    40\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "x = [10, 20, 30, 40]\n",
        "\n",
        "myvar = pd.Series(x)\n",
        "print(myvar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeSr_ozS6Wc5"
      },
      "source": [
        "10.  Create a DataFrame with columns `A` and `B`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ytbYen7w6Mmv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: [A, B]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    \"A\": [],\n",
        "    \"B\": []\n",
        "}\n",
        "\n",
        "dataframe = pd.DataFrame(data)\n",
        "print(dataframe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mAive8s7kfU"
      },
      "source": [
        "# Part 2: Working with a Dataset üõ•Ô∏è"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6daMs_F8SPx"
      },
      "source": [
        "1. Load the Titanic dataset from a local file and display the first five rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zi-ufFmj9e4h"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0          892         0       3   \n",
            "1          893         1       3   \n",
            "2          894         0       2   \n",
            "3          895         0       3   \n",
            "4          896         1       3   \n",
            "\n",
            "                                           Name     Sex   Age  SibSp  Parch  \\\n",
            "0                              Kelly, Mr. James    male  34.5      0      0   \n",
            "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
            "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
            "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
            "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
            "\n",
            "    Ticket     Fare Cabin Embarked  \n",
            "0   330911   7.8292   NaN        Q  \n",
            "1   363272   7.0000   NaN        S  \n",
            "2   240276   9.6875   NaN        Q  \n",
            "3   315154   8.6625   NaN        S  \n",
            "4  3101298  12.2875   NaN        S  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.options.display.max_rows = 5\n",
        "\n",
        "dataframe = pd.read_csv('titanic_dataset.csv')\n",
        "print(dataframe.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "405AKURC9sqB"
      },
      "source": [
        "2. Display the dataset's column names, data types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "88-8AT8W9uaI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 418 entries, 0 to 417\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  418 non-null    int64  \n",
            " 1   Survived     418 non-null    int64  \n",
            " 2   Pclass       418 non-null    int64  \n",
            " 3   Name         418 non-null    object \n",
            " 4   Sex          418 non-null    object \n",
            " 5   Age          332 non-null    float64\n",
            " 6   SibSp        418 non-null    int64  \n",
            " 7   Parch        418 non-null    int64  \n",
            " 8   Ticket       418 non-null    object \n",
            " 9   Fare         417 non-null    float64\n",
            " 10  Cabin        91 non-null     object \n",
            " 11  Embarked     418 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 39.3+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataframe = pd.read_csv('titanic_dataset.csv')\n",
        "\n",
        "print(dataframe.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh9FsKUx9-8S"
      },
      "source": [
        "3. Display the dataset's missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "olw7wFVH9-rG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     PassengerId  Survived  Pclass   Name    Sex    Age  SibSp  Parch  Ticket  \\\n",
            "0          False     False   False  False  False  False  False  False   False   \n",
            "1          False     False   False  False  False  False  False  False   False   \n",
            "..           ...       ...     ...    ...    ...    ...    ...    ...     ...   \n",
            "416        False     False   False  False  False   True  False  False   False   \n",
            "417        False     False   False  False  False   True  False  False   False   \n",
            "\n",
            "      Fare  Cabin  Embarked  \n",
            "0    False   True     False  \n",
            "1    False   True     False  \n",
            "..     ...    ...       ...  \n",
            "416  False   True     False  \n",
            "417  False   True     False  \n",
            "\n",
            "[418 rows x 12 columns]\n",
            "Number of Missing Values per Column \n",
            " PassengerId      0\n",
            "Survived         0\n",
            "              ... \n",
            "Cabin          327\n",
            "Embarked         0\n",
            "Length: 12, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataframe = pd.read_csv('titanic_dataset.csv')\n",
        "print(dataframe.isnull())\n",
        "print('Number of Missing Values per Column', '\\n', dataframe.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNAGBAXv-LXs"
      },
      "source": [
        "4. Display the `Name`, `Age`, and `Fare` columns from the dataset. (first 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "LNRu6hI7-dUV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                 Name   Age     Fare\n",
            "0                    Kelly, Mr. James  34.5   7.8292\n",
            "1    Wilkes, Mrs. James (Ellen Needs)  47.0   7.0000\n",
            "..                                ...   ...      ...\n",
            "416               Ware, Mr. Frederick   NaN   8.0500\n",
            "417          Peter, Master. Michael J   NaN  22.3583\n",
            "\n",
            "[418 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataframe = pd.read_csv('titanic_dataset.csv', usecols=['Name', 'Age', 'Fare'])\n",
        "\n",
        "print(dataframe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2iFTTa2-nAv"
      },
      "source": [
        " 5. Print the descriptive statistics of the Titanic dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "VvurbDoL-xJE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       PassengerId    Survived     Pclass        Age       SibSp       Parch  \\\n",
            "count       418.00  418.000000  418.00000  332.00000  418.000000  418.000000   \n",
            "mean       1100.50    0.363636    2.26555   30.27259    0.447368    0.392344   \n",
            "...            ...         ...        ...        ...         ...         ...   \n",
            "75%        1204.75    1.000000    3.00000   39.00000    1.000000    0.000000   \n",
            "max        1309.00    1.000000    3.00000   76.00000    8.000000    9.000000   \n",
            "\n",
            "             Fare  \n",
            "count  417.000000  \n",
            "mean    35.627188  \n",
            "...           ...  \n",
            "75%     31.500000  \n",
            "max    512.329200  \n",
            "\n",
            "[8 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataframe = pd.read_csv('titanic_dataset.csv')\n",
        "stats = dataframe.describe()\n",
        "\n",
        "print(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U95dijMI-9x1"
      },
      "source": [
        "6. Remove rows with missing values in the `Age` column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "mMKNND-E_jnL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     PassengerId  Survived  Pclass                              Name     Sex  \\\n",
            "0            892         0       3                  Kelly, Mr. James    male   \n",
            "1            893         1       3  Wilkes, Mrs. James (Ellen Needs)  female   \n",
            "..           ...       ...     ...                               ...     ...   \n",
            "414         1306         1       1      Oliva y Ocana, Dona. Fermina  female   \n",
            "415         1307         0       3      Saether, Mr. Simon Sivertsen    male   \n",
            "\n",
            "      Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \n",
            "0    34.5      0      0              330911    7.8292   NaN        Q  \n",
            "1    47.0      1      0              363272    7.0000   NaN        S  \n",
            "..    ...    ...    ...                 ...       ...   ...      ...  \n",
            "414  39.0      0      0            PC 17758  108.9000  C105        C  \n",
            "415  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
            "\n",
            "[332 rows x 12 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataframe = pd.read_csv('titanic_dataset.csv')\n",
        "newdataframe = dataframe.dropna(subset=['Age'], inplace=False)\n",
        "\n",
        "print(newdataframe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-2X_e-fFHI5"
      },
      "source": [
        "7. Remove duplicate rows from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "l2X-ym9eFIT-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     PassengerId  Survived  Pclass                              Name     Sex  \\\n",
            "0            892         0       3                  Kelly, Mr. James    male   \n",
            "1            893         1       3  Wilkes, Mrs. James (Ellen Needs)  female   \n",
            "..           ...       ...     ...                               ...     ...   \n",
            "416         1308         0       3               Ware, Mr. Frederick    male   \n",
            "417         1309         0       3          Peter, Master. Michael J    male   \n",
            "\n",
            "      Age  SibSp  Parch  Ticket     Fare Cabin Embarked  \n",
            "0    34.5      0      0  330911   7.8292   NaN        Q  \n",
            "1    47.0      1      0  363272   7.0000   NaN        S  \n",
            "..    ...    ...    ...     ...      ...   ...      ...  \n",
            "416   NaN      0      0  359309   8.0500   NaN        S  \n",
            "417   NaN      1      1    2668  22.3583   NaN        C  \n",
            "\n",
            "[418 rows x 12 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataframe = pd.read_csv('titanic_dataset.csv')\n",
        "print(dataframe.drop_duplicates(inplace = False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-SvrKnKFL1m"
      },
      "source": [
        "8. Compute and display the correlation matrix of the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v_OG5PPLUcL"
      },
      "source": [
        "# Part 2: Working with Case Studies\n",
        "\n",
        "When working on these case studies, **always ensure that your code is properly documented and clearly presented**. Follow these key principles:  \n",
        "\n",
        "### **1. Always Show Your Code**  \n",
        "- Every step of data exploration, cleaning, and analysis should include **visible code outputs**.  \n",
        "- Do not skip showing your process, as transparency is essential for reproducibility.  \n",
        "\n",
        "### **2. Proper Documentation is Necessary**  \n",
        "- Use **comments (`#`) in Python** to explain your code clearly.  \n",
        "- Add **Markdown cells** to describe each step before executing the code.  \n",
        "- Explain key findings in simple language to make the analysis easy to understand.  \n",
        "\n",
        "### **3. Use Readable and Organized Code**  \n",
        "- Follow a **step-by-step approach** to keep the notebook structured.  \n",
        "- Use **proper variable names** and avoid hardcoding values where possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOzxo0NoFZJ5"
      },
      "source": [
        "# **Case Study 1: Iris Flower Classification** üå∏  \n",
        "\n",
        "### **Background**  \n",
        "A botanical research institute wants to develop an automated system that classifies different species of **iris flowers** based on their **sepal and petal measurements**.  The dataset consists of **150 samples**, labeled as **Setosa, Versicolor, or Virginica**.  \n",
        "\n",
        "### **Problem Statement**  \n",
        "Can we use **sepal and petal dimensions** to correctly classify the **species of an iris flower**?  \n",
        "\n",
        "### **Task Description**  \n",
        "\n",
        "#### **1. Data Exploration**  \n",
        "- Load the dataset and display the first few rows.  \n",
        "- Identify any missing or inconsistent values.  \n",
        "\n",
        "#### **2. Data Cleaning**  \n",
        "- Check for missing values and handle them appropriately.  \n",
        "- Convert categorical species labels into a format suitable for analysis.  \n",
        "\n",
        "#### **3. Basic Data Analysis**  \n",
        "- Find the average sepal and petal dimensions for each species.  \n",
        "- Identify correlations between different flower measurements.  \n",
        "\n",
        "#### **4. Visualization**  \n",
        "- Create simple visualizations (e.g., histograms, scatter plots) to understand data distribution.  \n",
        "\n",
        "#### **5. Insights & Interpretation**  \n",
        "- Summarize key findings, such as which features best distinguish flower species.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "VpnqIg63LiAH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Dimensions \n",
            "                  sepal_length  sepal_width  petal_length  petal_width\n",
            "species                                                              \n",
            "Iris-setosa          5.010417     3.431250      1.462500     0.250000\n",
            "Iris-versicolor      5.936000     2.770000      4.260000     1.326000\n",
            "Iris-virginica       6.604082     2.979592      5.561224     2.028571 \n",
            "\n",
            "------------------------------------------------------------------\n",
            "Correlation \n",
            "               sepal_length  sepal_width  petal_length  petal_width\n",
            "sepal_length      1.000000    -0.109321      0.871305     0.817058\n",
            "sepal_width      -0.109321     1.000000     -0.421057    -0.356376\n",
            "petal_length      0.871305    -0.421057      1.000000     0.961883\n",
            "petal_width       0.817058    -0.356376      0.961883     1.000000 \n",
            "\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_13124\\1843424643.py:30: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
            "  plt.show()\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the iris dataset\n",
        "dataframe = pd.read_csv('iris_dataset.csv')\n",
        "\n",
        "# Clean Dataset\n",
        "newdataframe = dataframe.dropna().drop_duplicates() # Removes null and duplicated values from the dataset\n",
        "\n",
        "# Find the average sepal and petal dimensions from each species\n",
        "averageDimensions = newdataframe.groupby('species')[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].mean()\n",
        "print(\"Average Dimensions\", \"\\n\", averageDimensions, '\\n')\n",
        "print('------------------------------------------------------------------')\n",
        "\n",
        "# Identify the correlation between different flower measurements\n",
        "correlation = newdataframe.iloc[:, :-1].corr()\n",
        "print(\"Correlation\", \"\\n\", correlation, \"\\n\")\n",
        "\n",
        "# Running the .corr() function on the dataset results in an error because the\n",
        "# dataset contains a string column in the last part of the dataset and the corr()\n",
        "# function cannot accept strings.\n",
        "\n",
        "print('------------------------------------------------------------------')\n",
        "\n",
        "# Load visualization graph and save it as an image\n",
        "newdataframe.columns = [\"Sepal Length\", \"Sepal Width\", \"Petal Length\", \"Petal Width\", \"Species\"]\n",
        "\n",
        "correlation.plot()\n",
        "plt.savefig(\"correlation_graph.png\")\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Key Findings:\n",
        "\n",
        "- Iris Setosa has the smallest petal length and petal width, but has the largest sepal width.\n",
        "- Iris Virginica has the largest sepal length, petal length, and petal width.\n",
        "- Sepal dimensions are less useful in classification due to its negative correlation.\n",
        "- Petal dimesions are more useful in classification due io its positive correlation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acBPPZF1LN1S"
      },
      "source": [
        "# **Case Study 2: Netflix Content Analysis** üé¨  \n",
        "\n",
        "## **Background**  \n",
        "Netflix is a leading streaming platform with a vast collection of movies and TV shows. The company wants to analyze its **content library** to understand trends in **genres, release years, and regional distribution**.  \n",
        "\n",
        "## **Problem Statement**  \n",
        "How can we use **Netflix‚Äôs dataset** to gain insights into content distribution, popular genres, and release trends over time?  \n",
        "\n",
        "## **Task Description**  \n",
        "\n",
        "### **1. Data Exploration**  \n",
        "- Load the dataset and inspect its structure.  \n",
        "- Identify key columns such as title, genre, release year, and country.  \n",
        "\n",
        "### **2. Data Cleaning**  \n",
        "- Check for missing or incorrect values in key columns.  \n",
        "- Remove duplicates and format the date-related data properly.  \n",
        "\n",
        "### **3. Basic Data Analysis**  \n",
        "- Count the number of movies vs. TV shows.  \n",
        "- Identify the most common genres and countries producing content.  \n",
        "- Analyze the number of releases per year to observe trends.  \n",
        "\n",
        "### **4. Insights & Interpretation**  \n",
        "- Summarize key findings, such as trends in Netflix's content production over time.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "Vrd7hTehLigX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Movies vs. TV Shows\n",
            "type\n",
            "Movie      6131\n",
            "TV Show    2676\n",
            "Name: count, dtype: int64\n",
            "------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Common Genres\n",
            "listed_in\n",
            "International Movies      2752\n",
            "Dramas                    2427\n",
            "Comedies                  1674\n",
            "International TV Shows    1351\n",
            "Documentaries              869\n",
            "Name: count, dtype: int64\n",
            "------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Common Countries Producing Content\n",
            "country\n",
            "United States     3689\n",
            "India             1046\n",
            "United Kingdom     804\n",
            "Canada             445\n",
            "France             393\n",
            "Name: count, dtype: int64\n",
            "------------------------------------------------------------------\n",
            "release_year\n",
            "2018    1147\n",
            "2017    1032\n",
            "2019    1030\n",
            "2020     953\n",
            "2016     902\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "dataframe2 = pd.read_csv(\"netflix_dataset.csv\")\n",
        "\n",
        "# Data Cleaning\n",
        "newdataframe2 = dataframe2.drop_duplicates().dropna(subset=[\"title\", \"listed_in\", \"release_year\"])\n",
        "\n",
        "newdataframe2[\"date_added\"] = pd.to_datetime(newdataframe2[\"date_added\"], errors=\"coerce\")\n",
        "newdataframe2[\"date_added\"] = newdataframe2[\"date_added\"].dt.strftime(\"%B %d, %Y\")\n",
        "\n",
        "# Basic Data Analysis\n",
        "# Number of Movies vs. TV Shows\n",
        "type_count = newdataframe2[\"type\"].value_counts()\n",
        "print(\"Number of Movies vs. TV Shows\")\n",
        "print(type_count)\n",
        "print('------------------------------------------------------------------')\n",
        "\n",
        "# Most Common Genres and Countries Producing Content\n",
        "genre_count = newdataframe2[\"listed_in\"].str.split(\", \").explode().value_counts().head(5)\n",
        "print(\"\\n\\n\", \"Common Genres\")\n",
        "print(genre_count)\n",
        "print('------------------------------------------------------------------')\n",
        "\n",
        "country_count = newdataframe2[\"country\"].str.split(\", \").explode().value_counts().head(5)\n",
        "print(\"\\n\\n\", \"Common Countries Producing Content\")\n",
        "print(country_count)\n",
        "print('------------------------------------------------------------------')\n",
        "\n",
        "# Number of Releases per Year\n",
        "release_count = newdataframe2[\"release_year\"].value_counts().head()\n",
        "print(release_count)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Key Findings:\n",
        "\n",
        "- There is a higher number of movies created in Netflix than in TV shows.\n",
        "- The most common genres in Netflix are international movies, dramas, comedies, international TV shows, and documentaries (Top 5 only).\n",
        "- The most common countries that produce content in Netflix are the United States, India, United Kingdom, Canada, and France (Top 5 only).\n",
        "- Based on the data, it seems that there are many content released in 2019, 2020, and 2016, wherein 2019 has the most released content with 1030, followed by 953 in 2020 and 902 in 2016."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
